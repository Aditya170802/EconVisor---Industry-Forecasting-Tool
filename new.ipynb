{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "class ARIMAModel:\n",
    "    def __init__(self, file, column_index):\n",
    "        self.dataframe = self.process_dataset(file)\n",
    "        self.column_index = column_index-1\n",
    "\n",
    "    def process_dataset(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "        for i in range(1, 5):\n",
    "            if df.iloc[:, i].dtype == 'object':\n",
    "                df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "            df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def stationarity_tests(self, timeseries):\n",
    "        result_adf_trend = adfuller(timeseries, autolag='AIC')\n",
    "        adf_pvalue_trend = result_adf_trend[1]\n",
    "\n",
    "        num_diff_trend = 0\n",
    "        while adf_pvalue_trend > 0.05:\n",
    "            timeseries = timeseries.diff().dropna()\n",
    "            result_adf_trend = adfuller(timeseries, autolag='AIC')\n",
    "            adf_pvalue_trend = result_adf_trend[1]\n",
    "            num_diff_trend += 1\n",
    "\n",
    "        return timeseries, num_diff_trend\n",
    "\n",
    "    def print_acf_pacf_lags(self, timeseries, trend_diff):\n",
    "        acf_orig = acf(timeseries, fft=True, nlags=20)\n",
    "        pacf_orig = pacf(timeseries, nlags=20)\n",
    "\n",
    "        acf_diff_trend = acf(timeseries.diff().dropna(), fft=True, nlags=20)\n",
    "        pacf_diff_trend = pacf(timeseries.diff().dropna(), nlags=20)\n",
    "\n",
    "        def find_significant_lags(acf_values):\n",
    "            conf_interval = 1.96 / len(timeseries)**0.5\n",
    "            return [i for i, val in enumerate(acf_values) if abs(val) > conf_interval]\n",
    "\n",
    "        return [find_significant_lags(acf_orig), find_significant_lags(pacf_orig),\n",
    "                find_significant_lags(acf_diff_trend), find_significant_lags(pacf_diff_trend)]\n",
    "\n",
    "    def get_PDQ(self, my_list):\n",
    "        break_index = next((i for i, (a, b) in enumerate(zip(my_list, my_list[1:]), start=1) if b != a + 1), None)\n",
    "        if break_index is not None:\n",
    "            return len(my_list[:break_index])\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train_arima_model(self):\n",
    "        timeseries, trend_diff = self.stationarity_tests(self.dataframe.iloc[:, self.column_index])\n",
    "        lags_data = self.print_acf_pacf_lags(timeseries, trend_diff)\n",
    "\n",
    "        P = []\n",
    "        Q = []\n",
    "\n",
    "        if trend_diff != 0:\n",
    "            P = lags_data[3]\n",
    "            Q = lags_data[2]\n",
    "        else:\n",
    "            P = lags_data[1]\n",
    "            Q = lags_data[0]\n",
    "\n",
    "        if 0 in P:\n",
    "            P.remove(0)\n",
    "\n",
    "        if 0 in Q:\n",
    "            Q.remove(0)\n",
    "\n",
    "        p = self.get_PDQ(P)\n",
    "        q = self.get_PDQ(Q)\n",
    "        d = trend_diff\n",
    "\n",
    "        new_df = pd.DataFrame({self.dataframe.columns[self.column_index]: self.dataframe.iloc[:, self.column_index].values},\n",
    "                              index=self.dataframe.index)\n",
    "        \n",
    "        train_size = int(0.6 * len(new_df))\n",
    "        train_df, _ = new_df[:train_size], new_df[train_size:]\n",
    "        print(train_df.index[-1])\n",
    "\n",
    "        arima_model = ARIMA(train_df[train_df.columns[0]], order=(p, d, q)).fit()\n",
    "\n",
    "        return arima_model, train_df\n",
    "\n",
    "    def convert_to_datetime(self, year, quarter):\n",
    "        # Map quarter to the corresponding month\n",
    "        year = int(year)\n",
    "        quarter = int(quarter[-1])\n",
    "        month = (quarter - 1) * 3 + 1\n",
    "        \n",
    "        # Create a datetime object for the first day of the quarter\n",
    "        datetime_object = datetime(year, month, 1, 0, 0, 0)\n",
    "        \n",
    "        return datetime_object\n",
    "\n",
    "    def calculate_month_difference(self, datetime1, datetime2):\n",
    "        difference = relativedelta(datetime2, datetime1)\n",
    "        months_difference = difference.years * 12 + difference.months\n",
    "        return months_difference\n",
    "    \n",
    "    def forecast_data(self, year, quarter):\n",
    "        datetime2 = self.convert_to_datetime(year, quarter)\n",
    "        trained_model, train_df = self.train_arima_model()\n",
    "        result = int(self.calculate_month_difference(train_df.index[-1], datetime2)/3)\n",
    "        future_predictions = trained_model.forecast(result)\n",
    "        value = future_predictions.iloc[-1]\n",
    "        present_value = self.dataframe[self.dataframe.columns[self.column_index]][-1]\n",
    "        perc_change = ((value - present_value) / present_value) * 100\n",
    "        if perc_change > 0:\n",
    "            perc_change = f\"+{perc_change:.2f}%\"\n",
    "        else:\n",
    "            perc_change = f\"{perc_change:.2f}%\"\n",
    "        return value.round(3), perc_change\n",
    "    \n",
    "    def plot_data_with_prediction(self, target_index, xl, yl, year, quarter, predicted_value):\n",
    "        # Use a dark theme\n",
    "        plt.style.use('dark_background')\n",
    "\n",
    "        # Plot historical data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.dataframe.index, self.dataframe[self.dataframe.columns[target_index]], label='Historical Data', marker='o', color='lightblue', linestyle='-')\n",
    "\n",
    "        future_date = self.convert_to_datetime(year, quarter)\n",
    "\n",
    "        plt.scatter(future_date, predicted_value, color='red', label='Predicted Future Value', zorder=5)\n",
    "\n",
    "        # Annotate the predicted value on the plot\n",
    "        plt.text(future_date, predicted_value, f'{predicted_value:.2f}', color='red', ha='left', va='bottom', fontsize=10, bbox=dict(facecolor='black', edgecolor='none', boxstyle='round,pad=0.3'))\n",
    "\n",
    "        # Customize plot aesthetics\n",
    "        plt.title(xl, fontsize=14, color='white')\n",
    "        plt.xlabel('Year', fontsize=12, color='white')\n",
    "        plt.ylabel(yl, fontsize=12, color='white')\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Customize tick parameters\n",
    "        plt.tick_params(axis='both', which='both', colors='white')\n",
    "        return plt.gcf()\n",
    "\n",
    "    def create_and_save_plot(self, target_index, xl, yl, save_path, year, quarter, predicted_value):\n",
    "        plot = self.plot_data_with_prediction(target_index, xl, yl, year=year, quarter=quarter, predicted_value=predicted_value)\n",
    "        plot.savefig(save_path)\n",
    "        plt.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2300.889"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_model_instance = ARIMAModel(\"./Datasets/Agriculture/Agriculture Overall.csv\", 1)\n",
    "trained_model = arima_model_instance.train_arima_model()\n",
    "forec, change= arima_model_instance.forecast_data('2015', 'Q3')\n",
    "forec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./Datasets/Agriculture/Agriculture Overall.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(file).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'\n",
    "quarter = 'Q1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00\n",
      "2014-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency QS-OCT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "predictions = {f'{features[1]}': [0, 0], f'{features[2]}': [0, 0], f'{features[3]}': [0, 0], f'{features[4]}': [0, 0]}\n",
    "imgs_names = ['Production (Number)','Economy (Revenues)','Employment','GDP Contribution']\n",
    "for i in range(1, 5):\n",
    "    arima_model_instance = ARIMAModel(\"./Datasets/Agriculture/Agriculture Overall.csv\", i)\n",
    "    predicted_value, perc = arima_model_instance.forecast_data(year, quarter)\n",
    "    key = list(predictions.keys())[i-1]\n",
    "    predictions[key][0] = predicted_value\n",
    "    predictions[key][1] = perc\n",
    "    # xl = f'Hello {key} Forecast Plot'\n",
    "    # yl = f'{key}'\n",
    "    # arima_model_instance.create_and_save_plot(target_index=i-1, xl=xl, yl=yl, save_path=f'EconVisor---Industry-Forecasting-Tool/Static/ReportPlots/{imgs_names[i-1]}.png', year=year, quarter=quarter, predicted_value=predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Agricultural Production (in million tonnes)': [146.674, '+25.81%'],\n",
       " 'Total Agricultural Revenues (in billion INR)': [2835.536, '-62.75%'],\n",
       " 'Employment (in million people)': [58.95, '-5.07%'],\n",
       " 'GDP Contribution Percentage from Agriculture': [15.266, '+8.27%']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './Datasets/Agriculture/Agriculture Overall.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\3645048617.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "for i in range(1, 5):\n",
    "    if df.iloc[:, i].dtype == 'object':\n",
    "        df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "    df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "df.set_index(df.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Agricultural Production (in million tonnes)</th>\n",
       "      <th>Total Agricultural Revenues (in billion INR)</th>\n",
       "      <th>Employment (in million people)</th>\n",
       "      <th>GDP Contribution Percentage from Agriculture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>92.17</td>\n",
       "      <td>1610.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>94.55</td>\n",
       "      <td>1646.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>81.16</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-01</th>\n",
       "      <td>86.77</td>\n",
       "      <td>1561.1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>95.21</td>\n",
       "      <td>1697.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Agricultural Production (in million tonnes)  \\\n",
       "Quarterly Year                                                      \n",
       "2003-01-01                                                  92.17   \n",
       "2003-04-01                                                  94.55   \n",
       "2003-07-01                                                  81.16   \n",
       "2003-10-01                                                  86.77   \n",
       "2004-01-01                                                  95.21   \n",
       "\n",
       "               Total Agricultural Revenues (in billion INR)  \\\n",
       "Quarterly Year                                                \n",
       "2003-01-01                                           1610.2   \n",
       "2003-04-01                                           1646.8   \n",
       "2003-07-01                                           1485.0   \n",
       "2003-10-01                                           1561.1   \n",
       "2004-01-01                                           1697.5   \n",
       "\n",
       "                Employment (in million people)  \\\n",
       "Quarterly Year                                   \n",
       "2003-01-01                                54.2   \n",
       "2003-04-01                                54.3   \n",
       "2003-07-01                                54.4   \n",
       "2003-10-01                                54.5   \n",
       "2004-01-01                                54.6   \n",
       "\n",
       "                GDP Contribution Percentage from Agriculture  \n",
       "Quarterly Year                                                \n",
       "2003-01-01                                              18.4  \n",
       "2003-04-01                                              18.2  \n",
       "2003-07-01                                              17.9  \n",
       "2003-10-01                                              18.1  \n",
       "2004-01-01                                              18.3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\2642120126.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Agricultural Production (in million tonnes)</th>\n",
       "      <th>Total Agricultural Revenues (in billion INR)</th>\n",
       "      <th>Employment (in million people)</th>\n",
       "      <th>GDP Contribution Percentage from Agriculture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>92.17</td>\n",
       "      <td>1610.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>94.55</td>\n",
       "      <td>1646.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>81.16</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-01</th>\n",
       "      <td>86.77</td>\n",
       "      <td>1561.1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>95.21</td>\n",
       "      <td>1697.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Agricultural Production (in million tonnes)  \\\n",
       "Quarterly Year                                                      \n",
       "2003-01-01                                                  92.17   \n",
       "2003-04-01                                                  94.55   \n",
       "2003-07-01                                                  81.16   \n",
       "2003-10-01                                                  86.77   \n",
       "2004-01-01                                                  95.21   \n",
       "\n",
       "               Total Agricultural Revenues (in billion INR)  \\\n",
       "Quarterly Year                                                \n",
       "2003-01-01                                           1610.2   \n",
       "2003-04-01                                           1646.8   \n",
       "2003-07-01                                           1485.0   \n",
       "2003-10-01                                           1561.1   \n",
       "2004-01-01                                           1697.5   \n",
       "\n",
       "                Employment (in million people)  \\\n",
       "Quarterly Year                                   \n",
       "2003-01-01                                54.2   \n",
       "2003-04-01                                54.3   \n",
       "2003-07-01                                54.4   \n",
       "2003-10-01                                54.5   \n",
       "2004-01-01                                54.6   \n",
       "\n",
       "                GDP Contribution Percentage from Agriculture  \n",
       "Quarterly Year                                                \n",
       "2003-01-01                                              18.4  \n",
       "2003-04-01                                              18.2  \n",
       "2003-07-01                                              17.9  \n",
       "2003-10-01                                              18.1  \n",
       "2004-01-01                                              18.3  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "for i in range(1, 5):\n",
    "    if df.iloc[:, i].dtype == 'object':\n",
    "        df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "    df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "# df = df.iloc[:, [1]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(df.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Agricultural Revenues (in billion INR)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>1610.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>1646.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>1485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-01</th>\n",
       "      <td>1561.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>1697.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Total Agricultural Revenues (in billion INR)\n",
       "Quarterly Year                                             \n",
       "2003-01-01                                           1610.2\n",
       "2003-04-01                                           1646.8\n",
       "2003-07-01                                           1485.0\n",
       "2003-10-01                                           1561.1\n",
       "2004-01-01                                           1697.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract the 'Production' column as a 1D array\n",
    "production_values = df[df.columns[1]].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(production_values)\n",
    "\n",
    "# Create sequences and labels\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length:i+seq_length+1]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "seq_length = 3  # You can adjust this based on your needs\n",
    "X, y = create_sequences(df_scaled, seq_length)\n",
    "\n",
    "# Reshape for LSTM input (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 - 1s - loss: 0.1786 - 1s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "78/78 - 0s - loss: 0.1002 - 133ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "78/78 - 0s - loss: 0.0483 - 134ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "78/78 - 0s - loss: 0.0219 - 135ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "78/78 - 0s - loss: 0.0169 - 136ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "78/78 - 0s - loss: 0.0160 - 140ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "78/78 - 0s - loss: 0.0163 - 158ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "78/78 - 0s - loss: 0.0159 - 141ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "78/78 - 0s - loss: 0.0166 - 135ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "78/78 - 0s - loss: 0.0168 - 153ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "78/78 - 0s - loss: 0.0159 - 137ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "78/78 - 0s - loss: 0.0158 - 139ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "78/78 - 0s - loss: 0.0162 - 143ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "78/78 - 0s - loss: 0.0161 - 141ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "78/78 - 0s - loss: 0.0153 - 146ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "78/78 - 0s - loss: 0.0153 - 152ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "78/78 - 0s - loss: 0.0157 - 131ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "78/78 - 0s - loss: 0.0156 - 149ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "78/78 - 0s - loss: 0.0149 - 137ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "78/78 - 0s - loss: 0.0151 - 138ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "78/78 - 0s - loss: 0.0158 - 137ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "78/78 - 0s - loss: 0.0148 - 133ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "78/78 - 0s - loss: 0.0149 - 139ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "78/78 - 0s - loss: 0.0150 - 136ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "78/78 - 0s - loss: 0.0148 - 146ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "78/78 - 0s - loss: 0.0147 - 148ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "78/78 - 0s - loss: 0.0148 - 148ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "78/78 - 0s - loss: 0.0144 - 133ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "78/78 - 0s - loss: 0.0140 - 137ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "78/78 - 0s - loss: 0.0145 - 136ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "78/78 - 0s - loss: 0.0145 - 152ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "78/78 - 0s - loss: 0.0148 - 126ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "78/78 - 0s - loss: 0.0144 - 149ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "78/78 - 0s - loss: 0.0134 - 140ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "78/78 - 0s - loss: 0.0144 - 138ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "78/78 - 0s - loss: 0.0141 - 145ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "78/78 - 0s - loss: 0.0137 - 152ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "78/78 - 0s - loss: 0.0135 - 136ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "78/78 - 0s - loss: 0.0142 - 133ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "78/78 - 0s - loss: 0.0136 - 142ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "78/78 - 0s - loss: 0.0135 - 141ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "78/78 - 0s - loss: 0.0137 - 147ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "78/78 - 0s - loss: 0.0135 - 142ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "78/78 - 0s - loss: 0.0136 - 139ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "78/78 - 0s - loss: 0.0132 - 139ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "78/78 - 0s - loss: 0.0133 - 148ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "78/78 - 0s - loss: 0.0131 - 146ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "78/78 - 0s - loss: 0.0130 - 140ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "78/78 - 0s - loss: 0.0129 - 137ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "78/78 - 0s - loss: 0.0132 - 137ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "78/78 - 0s - loss: 0.0130 - 143ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "78/78 - 0s - loss: 0.0128 - 135ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "78/78 - 0s - loss: 0.0130 - 134ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "78/78 - 0s - loss: 0.0130 - 143ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "78/78 - 0s - loss: 0.0125 - 141ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "78/78 - 0s - loss: 0.0129 - 139ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "78/78 - 0s - loss: 0.0124 - 137ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "78/78 - 0s - loss: 0.0122 - 144ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "78/78 - 0s - loss: 0.0135 - 141ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "78/78 - 0s - loss: 0.0127 - 143ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "78/78 - 0s - loss: 0.0119 - 131ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "78/78 - 0s - loss: 0.0124 - 146ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "78/78 - 0s - loss: 0.0124 - 139ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "78/78 - 0s - loss: 0.0119 - 142ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "78/78 - 0s - loss: 0.0117 - 144ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "78/78 - 0s - loss: 0.0118 - 141ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "78/78 - 0s - loss: 0.0117 - 136ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "78/78 - 0s - loss: 0.0125 - 142ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "78/78 - 0s - loss: 0.0122 - 139ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "78/78 - 0s - loss: 0.0118 - 145ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "78/78 - 0s - loss: 0.0116 - 137ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "78/78 - 0s - loss: 0.0114 - 142ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "78/78 - 0s - loss: 0.0123 - 141ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "78/78 - 0s - loss: 0.0120 - 143ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "78/78 - 0s - loss: 0.0117 - 134ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "78/78 - 0s - loss: 0.0119 - 137ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "78/78 - 0s - loss: 0.0116 - 148ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "78/78 - 0s - loss: 0.0119 - 140ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "78/78 - 0s - loss: 0.0121 - 137ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "78/78 - 0s - loss: 0.0114 - 137ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "78/78 - 0s - loss: 0.0121 - 134ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "78/78 - 0s - loss: 0.0114 - 139ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "78/78 - 0s - loss: 0.0111 - 141ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "78/78 - 0s - loss: 0.0120 - 141ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "78/78 - 0s - loss: 0.0114 - 141ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "78/78 - 0s - loss: 0.0111 - 136ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "78/78 - 0s - loss: 0.0112 - 136ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "78/78 - 0s - loss: 0.0114 - 136ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "78/78 - 0s - loss: 0.0114 - 135ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "78/78 - 0s - loss: 0.0114 - 141ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "78/78 - 0s - loss: 0.0113 - 144ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "78/78 - 0s - loss: 0.0113 - 140ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "78/78 - 0s - loss: 0.0118 - 135ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "78/78 - 0s - loss: 0.0105 - 141ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "78/78 - 0s - loss: 0.0124 - 136ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "78/78 - 0s - loss: 0.0113 - 141ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "78/78 - 0s - loss: 0.0119 - 138ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "78/78 - 0s - loss: 0.0113 - 159ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "78/78 - 0s - loss: 0.0110 - 138ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "78/78 - 0s - loss: 0.0118 - 141ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29bbc6565e0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X, y, epochs=100, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 209ms/step\n",
      "Predicted Production for the next quarter: 8289.066\n"
     ]
    }
   ],
   "source": [
    "# Predict for the next quarter\n",
    "future_quarter = 1\n",
    "future_sequence = df_scaled[-seq_length:]\n",
    "future_sequence = future_sequence.reshape((1, seq_length, 1))\n",
    "\n",
    "future_prediction = model.predict(future_sequence)\n",
    "\n",
    "# Inverse transform the prediction\n",
    "future_prediction = scaler.inverse_transform(future_prediction)\n",
    "print(\"Predicted Production for the next quarter:\", future_prediction[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARIMAModel:\n",
    "    def __init__(self, file, column_index):\n",
    "        self.dataframe = self.process_dataset(file)\n",
    "        self.column_index = column_index-1\n",
    "\n",
    "    def process_dataset(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "        for i in range(1, 5):\n",
    "            if df.iloc[:, i].dtype == 'object':\n",
    "                df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "            df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def convert_to_datetime(self, year, quarter):\n",
    "            # Map quarter to the corresponding month\n",
    "            year = int(year)\n",
    "            quarter = int(quarter[-1])\n",
    "            month = (quarter - 1) * 3 + 1\n",
    "            \n",
    "            # Create a datetime object for the first day of the quarter\n",
    "            datetime_object = datetime(year, month, 1, 0, 0, 0)\n",
    "            \n",
    "            return datetime_object\n",
    "\n",
    "    def calculate_month_difference(self, datetime1, datetime2):\n",
    "        difference = relativedelta(datetime2, datetime1)\n",
    "        months_difference = difference.years * 12 + difference.months\n",
    "        return months_difference\n",
    "    \n",
    "    def train_lstm(self):\n",
    "        \n",
    "    \n",
    "    def forecast_data(self, year, quarter):\n",
    "        datetime2 = self.convert_to_datetime(year, quarter)\n",
    "        trained_model, train_df = self.train_arima_model()\n",
    "        result = int(self.calculate_month_difference(train_df.index[-1], datetime2)/3)\n",
    "        future_predictions = trained_model.forecast(result)\n",
    "        value = future_predictions.iloc[-1]\n",
    "        present_value = self.dataframe[self.dataframe.columns[self.column_index]][-1]\n",
    "        perc_change = ((value - present_value) / present_value) * 100\n",
    "        if perc_change > 0:\n",
    "            perc_change = f\"+{perc_change:.2f}%\"\n",
    "        else:\n",
    "            perc_change = f\"{perc_change:.2f}%\"\n",
    "        return value.round(3), perc_change\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\1103139602.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 - 2s - loss: 0.2280 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "73/73 - 0s - loss: 0.0320 - 185ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "73/73 - 0s - loss: 0.0228 - 176ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "73/73 - 0s - loss: 0.0215 - 183ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "73/73 - 0s - loss: 0.0211 - 178ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "73/73 - 0s - loss: 0.0209 - 165ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "73/73 - 0s - loss: 0.0206 - 161ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "73/73 - 0s - loss: 0.0203 - 165ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "73/73 - 0s - loss: 0.0197 - 160ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "73/73 - 0s - loss: 0.0203 - 163ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "73/73 - 0s - loss: 0.0192 - 163ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "73/73 - 0s - loss: 0.0190 - 163ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "73/73 - 0s - loss: 0.0193 - 165ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "73/73 - 0s - loss: 0.0180 - 164ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "73/73 - 0s - loss: 0.0175 - 164ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "73/73 - 0s - loss: 0.0176 - 168ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "73/73 - 0s - loss: 0.0177 - 161ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "73/73 - 0s - loss: 0.0170 - 162ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "73/73 - 0s - loss: 0.0172 - 164ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "73/73 - 0s - loss: 0.0154 - 166ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "73/73 - 0s - loss: 0.0156 - 157ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "73/73 - 0s - loss: 0.0155 - 162ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "73/73 - 0s - loss: 0.0148 - 162ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "73/73 - 0s - loss: 0.0144 - 162ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "73/73 - 0s - loss: 0.0142 - 166ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "73/73 - 0s - loss: 0.0138 - 167ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "73/73 - 0s - loss: 0.0135 - 163ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "73/73 - 0s - loss: 0.0133 - 160ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "73/73 - 0s - loss: 0.0133 - 162ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "73/73 - 0s - loss: 0.0133 - 169ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "73/73 - 0s - loss: 0.0120 - 162ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "73/73 - 0s - loss: 0.0119 - 165ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "73/73 - 0s - loss: 0.0124 - 158ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "73/73 - 0s - loss: 0.0125 - 160ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "73/73 - 0s - loss: 0.0119 - 163ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "73/73 - 0s - loss: 0.0108 - 163ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "73/73 - 0s - loss: 0.0115 - 163ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "73/73 - 0s - loss: 0.0101 - 158ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "73/73 - 0s - loss: 0.0109 - 161ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "73/73 - 0s - loss: 0.0105 - 162ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "73/73 - 0s - loss: 0.0109 - 163ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "73/73 - 0s - loss: 0.0105 - 163ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "73/73 - 0s - loss: 0.0112 - 161ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "73/73 - 0s - loss: 0.0104 - 162ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "73/73 - 0s - loss: 0.0105 - 165ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "73/73 - 0s - loss: 0.0103 - 164ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "73/73 - 0s - loss: 0.0100 - 160ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "73/73 - 0s - loss: 0.0108 - 163ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "73/73 - 0s - loss: 0.0097 - 160ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "73/73 - 0s - loss: 0.0103 - 161ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "73/73 - 0s - loss: 0.0102 - 173ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "73/73 - 0s - loss: 0.0101 - 159ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "73/73 - 0s - loss: 0.0102 - 165ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "73/73 - 0s - loss: 0.0098 - 165ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "73/73 - 0s - loss: 0.0097 - 163ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "73/73 - 0s - loss: 0.0099 - 163ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "73/73 - 0s - loss: 0.0099 - 163ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "73/73 - 0s - loss: 0.0102 - 163ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "73/73 - 0s - loss: 0.0096 - 158ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "73/73 - 0s - loss: 0.0100 - 173ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "73/73 - 0s - loss: 0.0097 - 164ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "73/73 - 0s - loss: 0.0101 - 167ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "73/73 - 0s - loss: 0.0098 - 163ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "73/73 - 0s - loss: 0.0095 - 158ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "73/73 - 0s - loss: 0.0098 - 160ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "73/73 - 0s - loss: 0.0096 - 159ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "73/73 - 0s - loss: 0.0091 - 161ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "73/73 - 0s - loss: 0.0095 - 167ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "73/73 - 0s - loss: 0.0101 - 162ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "73/73 - 0s - loss: 0.0096 - 165ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "73/73 - 0s - loss: 0.0094 - 165ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "73/73 - 0s - loss: 0.0096 - 165ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "73/73 - 0s - loss: 0.0094 - 165ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "73/73 - 0s - loss: 0.0095 - 161ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "73/73 - 0s - loss: 0.0099 - 164ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "73/73 - 0s - loss: 0.0100 - 165ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "73/73 - 0s - loss: 0.0094 - 164ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "73/73 - 0s - loss: 0.0095 - 163ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "73/73 - 0s - loss: 0.0099 - 164ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "73/73 - 0s - loss: 0.0091 - 163ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "73/73 - 0s - loss: 0.0098 - 166ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "73/73 - 0s - loss: 0.0093 - 161ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "73/73 - 0s - loss: 0.0094 - 163ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "73/73 - 0s - loss: 0.0089 - 157ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "73/73 - 0s - loss: 0.0097 - 163ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "73/73 - 0s - loss: 0.0095 - 165ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "73/73 - 0s - loss: 0.0094 - 162ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "73/73 - 0s - loss: 0.0099 - 163ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "73/73 - 0s - loss: 0.0097 - 161ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "73/73 - 0s - loss: 0.0099 - 165ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "73/73 - 0s - loss: 0.0092 - 178ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "73/73 - 0s - loss: 0.0092 - 165ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "73/73 - 0s - loss: 0.0090 - 163ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "73/73 - 0s - loss: 0.0090 - 154ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "73/73 - 0s - loss: 0.0087 - 166ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "73/73 - 0s - loss: 0.0090 - 166ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "73/73 - 0s - loss: 0.0090 - 163ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "73/73 - 0s - loss: 0.0093 - 160ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "73/73 - 0s - loss: 0.0092 - 161ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "73/73 - 0s - loss: 0.0095 - 170ms/epoch - 2ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "Predicted Production for the next 5 quarters: [131.4364  136.17099 111.68059 116.54924 132.30516]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "for i in range(1, 5):\n",
    "    if df.iloc[:, i].dtype == 'object':\n",
    "        df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "    df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "df = df[df.columns[selectedcolumn-1]].values.reshape(-1, 1)\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Create sequences and labels for predicting 5 quarters later\n",
    "def create_sequences(data, seq_length, future_steps):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length - future_steps + 1):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length:i+seq_length+future_steps]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "seq_length = 3  # You can adjust this based on your needs\n",
    "future_steps = 5  # Number of quarters to predict into the future\n",
    "\n",
    "X, y = create_sequences(df_scaled, seq_length, future_steps)\n",
    "\n",
    "# Reshape for LSTM input (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Define and train the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dense(future_steps))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X, y, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# Predict for the next 5 quarters\n",
    "future_quarters = 5\n",
    "future_sequence = df_scaled[-seq_length:]\n",
    "future_sequence = future_sequence.reshape((1, seq_length, 1))\n",
    "\n",
    "future_prediction = model.predict(future_sequence)\n",
    "\n",
    "# Inverse transform the prediction\n",
    "future_prediction = scaler.inverse_transform(future_prediction)\n",
    "print(\"Predicted Production for the next 5 quarters:\", future_prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\1073054949.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df.iloc[:, 0] = pd.to_datetime(self.df.iloc[:, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 - 2s - loss: 0.1937 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "73/73 - 0s - loss: 0.0218 - 198ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "73/73 - 0s - loss: 0.0114 - 198ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "73/73 - 0s - loss: 0.0066 - 202ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "73/73 - 0s - loss: 0.0051 - 199ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "73/73 - 0s - loss: 0.0048 - 211ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "73/73 - 0s - loss: 0.0051 - 204ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "73/73 - 0s - loss: 0.0044 - 206ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "73/73 - 0s - loss: 0.0045 - 202ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "73/73 - 0s - loss: 0.0049 - 202ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "73/73 - 0s - loss: 0.0047 - 197ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "73/73 - 0s - loss: 0.0045 - 191ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "73/73 - 0s - loss: 0.0046 - 200ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "73/73 - 0s - loss: 0.0046 - 203ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "73/73 - 0s - loss: 0.0044 - 216ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "73/73 - 0s - loss: 0.0045 - 211ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "73/73 - 0s - loss: 0.0044 - 213ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "73/73 - 0s - loss: 0.0044 - 215ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "73/73 - 0s - loss: 0.0045 - 256ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "73/73 - 0s - loss: 0.0045 - 226ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "73/73 - 0s - loss: 0.0044 - 218ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "73/73 - 0s - loss: 0.0043 - 217ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "73/73 - 0s - loss: 0.0048 - 205ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "73/73 - 0s - loss: 0.0045 - 198ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "73/73 - 0s - loss: 0.0046 - 184ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "73/73 - 0s - loss: 0.0042 - 183ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "73/73 - 0s - loss: 0.0042 - 170ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "73/73 - 0s - loss: 0.0042 - 170ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "73/73 - 0s - loss: 0.0042 - 170ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "73/73 - 0s - loss: 0.0044 - 176ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "73/73 - 0s - loss: 0.0043 - 175ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "73/73 - 0s - loss: 0.0046 - 179ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "73/73 - 0s - loss: 0.0041 - 179ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "73/73 - 0s - loss: 0.0043 - 176ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "73/73 - 0s - loss: 0.0042 - 176ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "73/73 - 0s - loss: 0.0041 - 167ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "73/73 - 0s - loss: 0.0042 - 170ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "73/73 - 0s - loss: 0.0041 - 172ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "73/73 - 0s - loss: 0.0041 - 171ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "73/73 - 0s - loss: 0.0044 - 170ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "73/73 - 0s - loss: 0.0043 - 174ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "73/73 - 0s - loss: 0.0040 - 167ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "73/73 - 0s - loss: 0.0043 - 171ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "73/73 - 0s - loss: 0.0042 - 173ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "73/73 - 0s - loss: 0.0043 - 170ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "73/73 - 0s - loss: 0.0041 - 177ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "73/73 - 0s - loss: 0.0041 - 185ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "73/73 - 0s - loss: 0.0043 - 169ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "73/73 - 0s - loss: 0.0041 - 168ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "73/73 - 0s - loss: 0.0040 - 167ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "73/73 - 0s - loss: 0.0039 - 163ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "73/73 - 0s - loss: 0.0040 - 163ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "73/73 - 0s - loss: 0.0040 - 160ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "73/73 - 0s - loss: 0.0039 - 170ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "73/73 - 0s - loss: 0.0041 - 167ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "73/73 - 0s - loss: 0.0039 - 171ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "73/73 - 0s - loss: 0.0041 - 173ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "73/73 - 0s - loss: 0.0039 - 173ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "73/73 - 0s - loss: 0.0036 - 174ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "73/73 - 0s - loss: 0.0037 - 174ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "73/73 - 0s - loss: 0.0038 - 168ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "73/73 - 0s - loss: 0.0038 - 173ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "73/73 - 0s - loss: 0.0039 - 169ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "73/73 - 0s - loss: 0.0037 - 172ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "73/73 - 0s - loss: 0.0038 - 169ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "73/73 - 0s - loss: 0.0044 - 173ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "73/73 - 0s - loss: 0.0037 - 160ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "73/73 - 0s - loss: 0.0035 - 171ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "73/73 - 0s - loss: 0.0036 - 170ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "73/73 - 0s - loss: 0.0036 - 167ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "73/73 - 0s - loss: 0.0036 - 171ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "73/73 - 0s - loss: 0.0033 - 169ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "73/73 - 0s - loss: 0.0035 - 175ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "73/73 - 0s - loss: 0.0035 - 165ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "73/73 - 0s - loss: 0.0034 - 159ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "73/73 - 0s - loss: 0.0035 - 163ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "73/73 - 0s - loss: 0.0039 - 165ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "73/73 - 0s - loss: 0.0034 - 162ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "73/73 - 0s - loss: 0.0034 - 158ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "73/73 - 0s - loss: 0.0033 - 158ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "73/73 - 0s - loss: 0.0033 - 164ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "73/73 - 0s - loss: 0.0035 - 162ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "73/73 - 0s - loss: 0.0032 - 158ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "73/73 - 0s - loss: 0.0037 - 160ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "73/73 - 0s - loss: 0.0031 - 159ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "73/73 - 0s - loss: 0.0033 - 159ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "73/73 - 0s - loss: 0.0034 - 154ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "73/73 - 0s - loss: 0.0031 - 154ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "73/73 - 0s - loss: 0.0029 - 161ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "73/73 - 0s - loss: 0.0033 - 154ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "73/73 - 0s - loss: 0.0033 - 155ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "73/73 - 0s - loss: 0.0033 - 157ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "73/73 - 0s - loss: 0.0034 - 167ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "73/73 - 0s - loss: 0.0031 - 165ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "73/73 - 0s - loss: 0.0035 - 161ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "73/73 - 0s - loss: 0.0029 - 156ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "73/73 - 0s - loss: 0.0030 - 156ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "73/73 - 0s - loss: 0.0028 - 162ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "73/73 - 0s - loss: 0.0029 - 180ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "73/73 - 0s - loss: 0.0027 - 161ms/epoch - 2ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "Predicted Production for the next 5 quarters: (14.138, '+0.27%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\1073054949.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  present_value = self.df[self.df.columns[self.selected_column]][-1]\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesPredictor:\n",
    "    def __init__(self, file, selected_column, seq_length=3,  epochs=100, batch_size=1):\n",
    "        self.file = file\n",
    "        self.selected_column = selected_column-1\n",
    "        self.seq_length = seq_length\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.df = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.model = None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Read CSV file and preprocess data\n",
    "        self.df = pd.read_csv(self.file)\n",
    "        self.df.iloc[:, 0] = pd.to_datetime(self.df.iloc[:, 0])\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            if self.df.iloc[:, i].dtype == 'object':\n",
    "                self.df.iloc[:, i] = self.df.iloc[:, i].str.replace(',', '')\n",
    "            self.df.iloc[:, i] = self.df.iloc[:, i].astype(float)\n",
    "\n",
    "        self.df.set_index(self.df.columns[0], inplace=True)\n",
    "\n",
    "        selected_data = self.df[self.df.columns[self.selected_column]].values.reshape(-1, 1)\n",
    "        self.df_scaled = self.scaler.fit_transform(selected_data)\n",
    "\n",
    "    def create_sequences(self, future_steps):\n",
    "        # Create sequences and labels for predicting future steps\n",
    "        sequences = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(self.df_scaled) - self.seq_length - future_steps + 1):\n",
    "            seq = self.df_scaled[i:i + self.seq_length]\n",
    "            label = self.df_scaled[i + self.seq_length:i + self.seq_length + future_steps]\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.X = np.array(sequences)\n",
    "        self.y = np.array(labels)\n",
    "\n",
    "        # Reshape for LSTM input (samples, time steps, features)\n",
    "        self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], 1))\n",
    "\n",
    "    def build_model(self, future_steps):\n",
    "        # Define and train the LSTM model\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(50, activation='relu', input_shape=(self.seq_length, 1)))\n",
    "        self.model.add(Dense(future_steps))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.model.fit(self.X, self.y, epochs=self.epochs, batch_size=self.batch_size, verbose=2)\n",
    "\n",
    "    def predict_future(self):\n",
    "        # Predict for future steps\n",
    "        future_sequence = self.df_scaled[-self.seq_length:]\n",
    "        future_sequence = future_sequence.reshape((1, self.seq_length, 1))\n",
    "\n",
    "        future_prediction = self.model.predict(future_sequence)\n",
    "\n",
    "        # Inverse transform the prediction\n",
    "        future_prediction = self.scaler.inverse_transform(future_prediction)\n",
    "        return future_prediction[0][-1]\n",
    "    \n",
    "    def convert_to_datetime(self, year, quarter):\n",
    "        # Map quarter to the corresponding month\n",
    "        year = int(year)\n",
    "        quarter = int(quarter[-1])\n",
    "        month = (quarter - 1) * 3 + 1\n",
    "        # Create a datetime object for the first day of the quarter\n",
    "        datetime_object = datetime(year, month, 1, 0, 0, 0)\n",
    "        \n",
    "        return datetime_object\n",
    "    \n",
    "    def calculate_month_difference(self, datetime1, datetime2):\n",
    "        difference = relativedelta(datetime2, datetime1)\n",
    "        months_difference = difference.years * 12 + difference.months\n",
    "        return months_difference\n",
    "    \n",
    "    def forecast_data(self, year, quarter):\n",
    "        datetime2 = self.convert_to_datetime(year, quarter)\n",
    "        result = int(self.calculate_month_difference(self.df.index[-1], datetime2)/3)\n",
    "        self.create_sequences(result)\n",
    "        self.build_model(result)\n",
    "        value = self.predict_future()\n",
    "\n",
    "        present_value = self.df[self.df.columns[self.selected_column]][-1]\n",
    "        perc_change = ((value - present_value) / present_value) * 100\n",
    "        if perc_change > 0:\n",
    "            perc_change = f\"+{perc_change:.2f}%\"\n",
    "        else:\n",
    "            perc_change = f\"{perc_change:.2f}%\"\n",
    "        return value.round(3), perc_change\n",
    "    \n",
    "    def process_dataset(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "        for i in range(1, 5):\n",
    "            if df.iloc[:, i].dtype == 'object':\n",
    "                df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "            df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = file\n",
    "selected_col = 4\n",
    "predictor = TimeSeriesPredictor(file=file_path, selected_column=selected_col)\n",
    "predictor.preprocess_data()\n",
    "future_predictions = predictor.forecast_data('2024', 'Q1')\n",
    "print(\"Predicted Production for the next 5 quarters:\", future_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\481153898.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df.iloc[:, 0] = pd.to_datetime(self.df.iloc[:, 0])\n"
     ]
    }
   ],
   "source": [
    "df3 = predictor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Agricultural Production (in million tonnes)</th>\n",
       "      <th>Total Agricultural Revenues (in billion INR)</th>\n",
       "      <th>Employment (in million people)</th>\n",
       "      <th>GDP Contribution Percentage from Agriculture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>92.17</td>\n",
       "      <td>1610.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>94.55</td>\n",
       "      <td>1646.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>81.16</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-01</th>\n",
       "      <td>86.77</td>\n",
       "      <td>1561.1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>95.21</td>\n",
       "      <td>1697.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Agricultural Production (in million tonnes)  \\\n",
       "Quarterly Year                                                      \n",
       "2003-01-01                                                  92.17   \n",
       "2003-04-01                                                  94.55   \n",
       "2003-07-01                                                  81.16   \n",
       "2003-10-01                                                  86.77   \n",
       "2004-01-01                                                  95.21   \n",
       "\n",
       "               Total Agricultural Revenues (in billion INR)  \\\n",
       "Quarterly Year                                                \n",
       "2003-01-01                                           1610.2   \n",
       "2003-04-01                                           1646.8   \n",
       "2003-07-01                                           1485.0   \n",
       "2003-10-01                                           1561.1   \n",
       "2004-01-01                                           1697.5   \n",
       "\n",
       "                Employment (in million people)  \\\n",
       "Quarterly Year                                   \n",
       "2003-01-01                                54.2   \n",
       "2003-04-01                                54.3   \n",
       "2003-07-01                                54.4   \n",
       "2003-10-01                                54.5   \n",
       "2004-01-01                                54.6   \n",
       "\n",
       "                GDP Contribution Percentage from Agriculture  \n",
       "Quarterly Year                                                \n",
       "2003-01-01                                              18.4  \n",
       "2003-04-01                                              18.2  \n",
       "2003-07-01                                              17.9  \n",
       "2003-10-01                                              18.1  \n",
       "2004-01-01                                              18.3  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\4008133201.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Agricultural Production (in million tonnes)</th>\n",
       "      <th>Total Agricultural Revenues (in billion INR)</th>\n",
       "      <th>Employment (in million people)</th>\n",
       "      <th>GDP Contribution Percentage from Agriculture</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarterly Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>92.17</td>\n",
       "      <td>1610.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>94.55</td>\n",
       "      <td>1646.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>81.16</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-01</th>\n",
       "      <td>86.77</td>\n",
       "      <td>1561.1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>95.21</td>\n",
       "      <td>1697.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Agricultural Production (in million tonnes)  \\\n",
       "Quarterly Year                                                      \n",
       "2003-01-01                                                  92.17   \n",
       "2003-04-01                                                  94.55   \n",
       "2003-07-01                                                  81.16   \n",
       "2003-10-01                                                  86.77   \n",
       "2004-01-01                                                  95.21   \n",
       "\n",
       "               Total Agricultural Revenues (in billion INR)  \\\n",
       "Quarterly Year                                                \n",
       "2003-01-01                                           1610.2   \n",
       "2003-04-01                                           1646.8   \n",
       "2003-07-01                                           1485.0   \n",
       "2003-10-01                                           1561.1   \n",
       "2004-01-01                                           1697.5   \n",
       "\n",
       "                Employment (in million people)  \\\n",
       "Quarterly Year                                   \n",
       "2003-01-01                                54.2   \n",
       "2003-04-01                                54.3   \n",
       "2003-07-01                                54.4   \n",
       "2003-10-01                                54.5   \n",
       "2004-01-01                                54.6   \n",
       "\n",
       "                GDP Contribution Percentage from Agriculture  \n",
       "Quarterly Year                                                \n",
       "2003-01-01                                              18.4  \n",
       "2003-04-01                                              18.2  \n",
       "2003-07-01                                              17.9  \n",
       "2003-10-01                                              18.1  \n",
       "2004-01-01                                              18.3  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "for i in range(1, 5):\n",
    "    if df.iloc[:, i].dtype == 'object':\n",
    "        df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "    df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df['Production'] = scaler.fit_transform(df[['Production']])\n",
    "\n",
    "# Prepare data for RNN\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data.iloc[i:i+seq_length]['Production'].values\n",
    "        label = data.iloc[i+seq_length]['Production']\n",
    "        sequences.append(seq)\n",
    "        targets.append(label)\n",
    "\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Set sequence length\n",
    "sequence_length = 2\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(df, sequence_length)\n",
    "\n",
    "# Reshape input data for RNN\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(sequence_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "future_steps = 3  # Number of future steps to predict\n",
    "test_input = df[-sequence_length:].values.reshape((1, sequence_length, 1))\n",
    "predictions = []\n",
    "\n",
    "for _ in range(future_steps):\n",
    "    pred = model.predict(test_input)\n",
    "    predictions.append(pred)\n",
    "    test_input = np.append(test_input[:, 1:, :], [[pred]], axis=1)\n",
    "\n",
    "# Inverse transform the predictions to the original scale\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(df.index, df['Production'], label='Original Data')\n",
    "plt.plot(pd.date_range(start=df.index[-1], periods=future_steps+1, freq='Q'), predictions, label='Future Predictions', linestyle='dashed')\n",
    "plt.xlabel('QuarterlyYear')\n",
    "plt.ylabel('Production')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "class RNNPredictor:\n",
    "    def __init__(self, file, selected_column, seq_length=3, epochs=100, batch_size=1):\n",
    "        self.file = file\n",
    "        self.selected_column = selected_column - 1\n",
    "        self.seq_length = seq_length\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.df = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.model = None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Read CSV file and preprocess data\n",
    "        self.df = pd.read_csv(self.file)\n",
    "        self.df.iloc[:, 0] = pd.to_datetime(self.df.iloc[:, 0])\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            if self.df.iloc[:, i].dtype == 'object':\n",
    "                self.df.iloc[:, i] = self.df.iloc[:, i].str.replace(',', '')\n",
    "            self.df.iloc[:, i] = self.df.iloc[:, i].astype(float)\n",
    "\n",
    "        self.df.set_index(self.df.columns[0], inplace=True)\n",
    "\n",
    "        selected_data = self.df[self.df.columns[self.selected_column]].values.reshape(-1, 1)\n",
    "        self.df_scaled = self.scaler.fit_transform(selected_data)\n",
    "\n",
    "    def create_sequences(self, future_steps):\n",
    "        # Create sequences and labels for predicting future steps\n",
    "        sequences = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(self.df_scaled) - self.seq_length - future_steps + 1):\n",
    "            seq = self.df_scaled[i:i + self.seq_length]\n",
    "            label = self.df_scaled[i + self.seq_length:i + self.seq_length + future_steps]\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.X = np.array(sequences)\n",
    "        self.y = np.array(labels)\n",
    "\n",
    "        # Reshape for RNN input (samples, time steps, features)\n",
    "        self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], 1))\n",
    "\n",
    "    def build_model(self, future_steps):\n",
    "        # Define and train the RNN model\n",
    "        self.model = Sequential()\n",
    "        self.model.add(SimpleRNN(50, activation='relu', input_shape=(self.seq_length, 1)))\n",
    "        self.model.add(Dense(future_steps))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        self.model.fit(self.X, self.y, epochs=self.epochs, batch_size=self.batch_size, verbose=2)\n",
    "\n",
    "    def predict_future(self):\n",
    "        # Predict for future steps\n",
    "        future_sequence = self.df_scaled[-self.seq_length:]\n",
    "        future_sequence = future_sequence.reshape((1, self.seq_length, 1))\n",
    "\n",
    "        future_prediction = self.model.predict(future_sequence)\n",
    "\n",
    "        # Inverse transform the prediction\n",
    "        future_prediction = self.scaler.inverse_transform(future_prediction)\n",
    "        return future_prediction[0][-1]\n",
    "\n",
    "    def forecast_data(self, year, quarter):\n",
    "        datetime2 = self.convert_to_datetime(year, quarter)\n",
    "        result = int(self.calculate_month_difference(self.df.index[-1], datetime2) / 3)\n",
    "        self.create_sequences(result)\n",
    "        self.build_model(result)\n",
    "        value = self.predict_future()\n",
    "\n",
    "        present_value = self.df[self.df.columns[self.selected_column]][-1]\n",
    "        perc_change = ((value - present_value) / present_value) * 100\n",
    "        if perc_change > 0:\n",
    "            perc_change = f\"+{perc_change:.2f}%\"\n",
    "        else:\n",
    "            perc_change = f\"{perc_change:.2f}%\"\n",
    "        return value.round(3), perc_change\n",
    "\n",
    "    def convert_to_datetime(self, year, quarter):\n",
    "        # Map quarter to the corresponding month\n",
    "        year = int(year)\n",
    "        quarter = int(quarter[-1])\n",
    "        month = (quarter - 1) * 3 + 1\n",
    "        # Create a datetime object for the first day of the quarter\n",
    "        datetime_object = datetime(year, month, 1, 0, 0, 0)\n",
    "\n",
    "        return datetime_object\n",
    "\n",
    "    def calculate_month_difference(self, datetime1, datetime2):\n",
    "        difference = relativedelta(datetime2, datetime1)\n",
    "        months_difference = difference.years * 12 + difference.months\n",
    "        return months_difference\n",
    "\n",
    "    def process_dataset(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "        for i in range(1, 5):\n",
    "            if df.iloc[:, i].dtype == 'object':\n",
    "                df.iloc[:, i] = df.iloc[:, i].str.replace(',', '')\n",
    "            df.iloc[:, i] = df.iloc[:, i].astype(float)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\4236529242.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df.iloc[:, 0] = pd.to_datetime(self.df.iloc[:, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 - 2s - loss: 0.1180 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "73/73 - 0s - loss: 0.0177 - 183ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "73/73 - 0s - loss: 0.0147 - 187ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "73/73 - 0s - loss: 0.0136 - 188ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "73/73 - 0s - loss: 0.0131 - 188ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "73/73 - 0s - loss: 0.0119 - 187ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "73/73 - 0s - loss: 0.0117 - 192ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "73/73 - 0s - loss: 0.0109 - 189ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "73/73 - 0s - loss: 0.0113 - 193ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "73/73 - 0s - loss: 0.0101 - 185ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "73/73 - 0s - loss: 0.0102 - 192ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "73/73 - 0s - loss: 0.0110 - 205ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "73/73 - 0s - loss: 0.0111 - 195ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "73/73 - 0s - loss: 0.0096 - 199ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "73/73 - 0s - loss: 0.0102 - 203ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "73/73 - 0s - loss: 0.0100 - 204ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "73/73 - 0s - loss: 0.0105 - 217ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "73/73 - 0s - loss: 0.0098 - 192ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "73/73 - 0s - loss: 0.0095 - 199ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "73/73 - 0s - loss: 0.0106 - 203ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "73/73 - 0s - loss: 0.0109 - 205ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "73/73 - 0s - loss: 0.0098 - 197ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "73/73 - 0s - loss: 0.0097 - 190ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "73/73 - 0s - loss: 0.0093 - 202ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "73/73 - 0s - loss: 0.0093 - 203ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "73/73 - 0s - loss: 0.0092 - 194ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "73/73 - 0s - loss: 0.0095 - 200ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "73/73 - 0s - loss: 0.0090 - 177ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "73/73 - 0s - loss: 0.0091 - 175ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "73/73 - 0s - loss: 0.0089 - 172ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "73/73 - 0s - loss: 0.0092 - 172ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "73/73 - 0s - loss: 0.0096 - 172ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "73/73 - 0s - loss: 0.0091 - 168ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "73/73 - 0s - loss: 0.0089 - 166ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "73/73 - 0s - loss: 0.0091 - 167ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "73/73 - 0s - loss: 0.0088 - 167ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "73/73 - 0s - loss: 0.0079 - 167ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "73/73 - 0s - loss: 0.0083 - 166ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "73/73 - 0s - loss: 0.0082 - 163ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "73/73 - 0s - loss: 0.0079 - 165ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "73/73 - 0s - loss: 0.0082 - 164ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "73/73 - 0s - loss: 0.0085 - 160ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "73/73 - 0s - loss: 0.0078 - 154ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "73/73 - 0s - loss: 0.0078 - 157ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "73/73 - 0s - loss: 0.0089 - 153ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "73/73 - 0s - loss: 0.0073 - 148ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "73/73 - 0s - loss: 0.0082 - 167ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "73/73 - 0s - loss: 0.0071 - 162ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "73/73 - 0s - loss: 0.0077 - 160ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "73/73 - 0s - loss: 0.0072 - 168ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "73/73 - 0s - loss: 0.0071 - 183ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "73/73 - 0s - loss: 0.0074 - 192ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "73/73 - 0s - loss: 0.0079 - 193ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "73/73 - 0s - loss: 0.0073 - 201ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "73/73 - 0s - loss: 0.0070 - 186ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "73/73 - 0s - loss: 0.0068 - 190ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "73/73 - 0s - loss: 0.0069 - 183ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "73/73 - 0s - loss: 0.0076 - 183ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "73/73 - 0s - loss: 0.0073 - 187ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "73/73 - 0s - loss: 0.0077 - 187ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "73/73 - 0s - loss: 0.0066 - 190ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "73/73 - 0s - loss: 0.0070 - 230ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "73/73 - 0s - loss: 0.0068 - 188ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "73/73 - 0s - loss: 0.0069 - 179ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "73/73 - 0s - loss: 0.0067 - 185ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "73/73 - 0s - loss: 0.0064 - 209ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "73/73 - 0s - loss: 0.0070 - 171ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "73/73 - 0s - loss: 0.0067 - 177ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "73/73 - 0s - loss: 0.0062 - 235ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "73/73 - 0s - loss: 0.0066 - 183ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "73/73 - 0s - loss: 0.0070 - 182ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "73/73 - 0s - loss: 0.0073 - 183ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "73/73 - 0s - loss: 0.0061 - 183ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "73/73 - 0s - loss: 0.0063 - 184ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "73/73 - 0s - loss: 0.0066 - 184ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "73/73 - 0s - loss: 0.0063 - 187ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "73/73 - 0s - loss: 0.0062 - 189ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "73/73 - 0s - loss: 0.0060 - 193ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "73/73 - 0s - loss: 0.0070 - 186ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "73/73 - 0s - loss: 0.0067 - 190ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "73/73 - 0s - loss: 0.0060 - 180ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "73/73 - 0s - loss: 0.0061 - 190ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "73/73 - 0s - loss: 0.0059 - 183ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "73/73 - 0s - loss: 0.0061 - 189ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "73/73 - 0s - loss: 0.0065 - 188ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "73/73 - 0s - loss: 0.0063 - 184ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "73/73 - 0s - loss: 0.0062 - 191ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "73/73 - 0s - loss: 0.0058 - 188ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "73/73 - 0s - loss: 0.0060 - 187ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "73/73 - 0s - loss: 0.0062 - 184ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "73/73 - 0s - loss: 0.0068 - 189ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "73/73 - 0s - loss: 0.0064 - 186ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "73/73 - 0s - loss: 0.0059 - 187ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "73/73 - 0s - loss: 0.0056 - 181ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "73/73 - 0s - loss: 0.0057 - 186ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "73/73 - 0s - loss: 0.0059 - 183ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "73/73 - 0s - loss: 0.0063 - 190ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "73/73 - 0s - loss: 0.0057 - 190ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "73/73 - 0s - loss: 0.0058 - 191ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "73/73 - 0s - loss: 0.0059 - 188ms/epoch - 3ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "Predicted Production for the next 5 quarters: (132.354, '+13.53%')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12468\\4236529242.py:77: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  present_value = self.df[self.df.columns[self.selected_column]][-1]\n"
     ]
    }
   ],
   "source": [
    "file_path = file\n",
    "selected_col = 1\n",
    "predictor = RNNPredictor(file=file_path, selected_column=selected_col)\n",
    "predictor.preprocess_data()\n",
    "future_predictions = predictor.forecast_data('2024', 'Q1')\n",
    "print(\"Predicted Production:\", future_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
